{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df75983d",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Connect to the CARLA server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e961b4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T23:05:32.323703Z",
     "start_time": "2025-04-07T23:05:30.178945Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "time-out of 10000ms while waiting for the simulator, make sure the simulator is ready and connected to localhost:2000",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m client \u001b[38;5;241m=\u001b[39m carla\u001b[38;5;241m.\u001b[39mClient(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocalhost\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m2000\u001b[39m)\n\u001b[0;32m      7\u001b[0m client\u001b[38;5;241m.\u001b[39mset_timeout(\u001b[38;5;241m10.0\u001b[39m)  \u001b[38;5;66;03m# seconds\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m world \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_world\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnected to world:\u001b[39m\u001b[38;5;124m\"\u001b[39m, world\u001b[38;5;241m.\u001b[39mget_map()\u001b[38;5;241m.\u001b[39mname)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: time-out of 10000ms while waiting for the simulator, make sure the simulator is ready and connected to localhost:2000"
     ]
    }
   ],
   "source": [
    "import carla\n",
    "import random\n",
    "import time\n",
    "\n",
    "# Prerequisite: CARLA must already be running in the background\n",
    "client = carla.Client('127.0.0.1', 2000)\n",
    "client.set_timeout(10.0)  # seconds\n",
    "\n",
    "world = client.get_world()\n",
    "print(\"Connected to world:\", world.get_map().name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c176fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T23:04:29.126622Z",
     "start_time": "2025-04-07T23:04:28.810620Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Display all available maps\n",
    "available_maps = client.get_available_maps()\n",
    "for i, map_name in enumerate(available_maps):\n",
    "    print(f\"{i+1}. {map_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f22354",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T23:04:42.300477Z",
     "start_time": "2025-04-07T23:04:33.150480Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Warning: Changing the map takes a few seconds and resets the world\n",
    "client.load_world('/Game/Carla/Maps/Town01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3861246",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T23:05:34.524557Z",
     "start_time": "2025-04-07T23:05:34.455057Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Example: Spawn a Tesla Model 3 blueprint\n",
    "blueprint_library = world.get_blueprint_library()\n",
    "vehicle_bp = blueprint_library.find('vehicle.tesla.model3')\n",
    "spawn_points = world.get_map().get_spawn_points()\n",
    "vehicle = world.spawn_actor(vehicle_bp, random.choice(spawn_points))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f155f2",
   "metadata": {},
   "source": [
    "> ðŸ’¡ **Small Task:** Find the spawned vehicle on the map.  \n",
    "> You can look around and move using the mouse and the WASD keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276f7dee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T23:09:12.831586Z",
     "start_time": "2025-04-07T23:09:12.814083Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Set weather conditions\n",
    "weather = carla.WeatherParameters.HardRainNight\n",
    "world.set_weather(weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00abe06f",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Introduction to Pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fccaaee",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Very Basic Pygame script that displays a blank white canvas\n",
    "import pygame\n",
    "\n",
    "# Initialize Pygame\n",
    "pygame.init()\n",
    "\n",
    "# Define window size\n",
    "WIDTH, HEIGHT = 800, 600\n",
    "screen = pygame.display.set_mode((WIDTH, HEIGHT))\n",
    "pygame.display.set_caption(\"White Canvas in Pygame\")\n",
    "\n",
    "# Background color (white)\n",
    "WHITE = (255, 255, 255)\n",
    "\n",
    "# Main loop\n",
    "running = True\n",
    "while running:\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            running = False  # Exit when the window is closed\n",
    "    \n",
    "    # Fill the screen with white\n",
    "    screen.fill(WHITE)\n",
    "    \n",
    "    # Update the display\n",
    "    pygame.display.flip()\n",
    "\n",
    "# Quit Pygame\n",
    "pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311a0288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying a Car and a Person\n",
    "\n",
    "import pygame\n",
    "\n",
    "# Initialize Pygame\n",
    "pygame.init()\n",
    "\n",
    "# Define window size\n",
    "WIDTH, HEIGHT = 800, 600\n",
    "screen = pygame.display.set_mode((WIDTH, HEIGHT))\n",
    "pygame.display.set_caption(\"Car and Person on Canvas\")\n",
    "\n",
    "# Background color (white)\n",
    "WHITE = (255, 255, 255)\n",
    "\n",
    "# Load images (example images of a car and a person)\n",
    "car_img = pygame.image.load(\"media/car.png\")\n",
    "person_img = pygame.image.load(\"media/person.png\")\n",
    "\n",
    "# Optionally scale images to fit the window\n",
    "car_img = pygame.transform.scale(car_img, (300, 240))\n",
    "person_img = pygame.transform.scale(person_img, (300, 300))\n",
    "\n",
    "# Main loop\n",
    "running = True\n",
    "while running:\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            running = False  # Exit when the window is closed\n",
    "        elif event.type == pygame.KEYDOWN and event.key == pygame.K_ESCAPE:\n",
    "            running = False  # Exit when ESC is pressed\n",
    "    \n",
    "    # Fill the screen with white\n",
    "    screen.fill(WHITE)\n",
    "    \n",
    "    # Draw images on the canvas\n",
    "    screen.blit(car_img, (200, 300))   # Car at position (200, 300)\n",
    "    screen.blit(person_img, (500, 300)) # Person at position (500, 300)\n",
    "    \n",
    "    # Update the display\n",
    "    pygame.display.flip()\n",
    "\n",
    "# Quit Pygame\n",
    "pygame.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d8642c",
   "metadata": {},
   "source": [
    "# Introduction to YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b365776",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T23:43:41.215070Z",
     "start_time": "2025-04-07T23:43:29.463586Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLOv8 model (nano version for fast performance)\n",
    "model = YOLO('model/yolov8n.pt')\n",
    "image_path = 'media/car.png'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Run object detection\n",
    "results = model(image)\n",
    "\n",
    "# Draw bounding boxes and labels on the image\n",
    "annotated_image = results[0].plot()\n",
    "\n",
    "# Display the result\n",
    "cv2.imshow('YOLOv8 Detection', annotated_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570ea4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load YOLOv8 model (default is YOLOv8n = \"nano\" for good performance)\n",
    "model = YOLO('model/yolov8n.pt')\n",
    "\n",
    "# Open video stream (0 = webcam, or provide a file path)\n",
    "cap = cv2.VideoCapture(\"media/hamilton_clip.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0348f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        print(\"No frame received. Stream ended.\")\n",
    "        break\n",
    "\n",
    "    # Run YOLO inference\n",
    "    results = model(frame, verbose=False)\n",
    "    annotated_frame = results[0].plot()\n",
    "\n",
    "    # Display the annotated frame\n",
    "    cv2.imshow(\"YOLO Object Detection\", annotated_frame)\n",
    "\n",
    "    # Press 'q' to quit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e161a079",
   "metadata": {},
   "source": [
    "# Threaded Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a917613",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "import queue\n",
    "\n",
    "# Background task that processes data from the input queue\n",
    "def background_worker(input_queue, output_queue):\n",
    "    while True:\n",
    "        item = input_queue.get()\n",
    "        if item is None:\n",
    "            break  # Exit the thread if a termination signal is received\n",
    "        # Simulate some processing (e.g., image analysis)\n",
    "        processed = item.upper()  # Here, just convert text to uppercase\n",
    "        time.sleep(0.5)  # Simulate processing time\n",
    "        output_queue.put(processed)\n",
    "\n",
    "# Queues for thread-safe communication between main thread and worker\n",
    "input_queue = queue.Queue()\n",
    "output_queue = queue.Queue()\n",
    "\n",
    "# Start the background thread\n",
    "thread = threading.Thread(target=background_worker,args=(input_queue, output_queue))\n",
    "thread.start()\n",
    "\n",
    "# Main thread: generate and send data to the worker\n",
    "for i in range(5):\n",
    "    text = f\"message {i}\"\n",
    "    print(f\"[Main] Sending: {text}\")\n",
    "    input_queue.put(text)\n",
    "    time.sleep(0.2)  # Main thread is faster than the worker\n",
    "\n",
    "# Retrieve results from the output queue\n",
    "for _ in range(5):\n",
    "    result = output_queue.get()\n",
    "    print(f\"[Main] Received: {result}\")\n",
    "\n",
    "# Send termination signal and wait for thread to finish\n",
    "input_queue.put(None)\n",
    "thread.join()\n",
    "print(\"Thread finished.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1ea73a",
   "metadata": {},
   "source": [
    "# TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a407c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.8.20)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8l.pt to 'yolov8l.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 83.7M/83.7M [00:33<00:00, 2.61MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 291.4ms\n",
      "Speed: 2.0ms preprocess, 291.4ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 297.6ms\n",
      "Speed: 1.4ms preprocess, 297.6ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 315.3ms\n",
      "Speed: 1.1ms preprocess, 315.3ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 280.9ms\n",
      "Speed: 1.1ms preprocess, 280.9ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 320.5ms\n",
      "Speed: 1.3ms preprocess, 320.5ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 319.5ms\n",
      "Speed: 2.5ms preprocess, 319.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 296.7ms\n",
      "Speed: 1.1ms preprocess, 296.7ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 292.4ms\n",
      "Speed: 1.2ms preprocess, 292.4ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 276.3ms\n",
      "Speed: 1.2ms preprocess, 276.3ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 276.1ms\n",
      "Speed: 1.2ms preprocess, 276.1ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 275.2ms\n",
      "Speed: 1.2ms preprocess, 275.2ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 278.8ms\n",
      "Speed: 1.1ms preprocess, 278.8ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 276.7ms\n",
      "Speed: 1.1ms preprocess, 276.7ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 280.5ms\n",
      "Speed: 1.2ms preprocess, 280.5ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 283.0ms\n",
      "Speed: 1.1ms preprocess, 283.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 271.0ms\n",
      "Speed: 1.2ms preprocess, 271.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 280.9ms\n",
      "Speed: 1.1ms preprocess, 280.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 285.8ms\n",
      "Speed: 1.1ms preprocess, 285.8ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 280.5ms\n",
      "Speed: 1.1ms preprocess, 280.5ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 249.7ms\n",
      "Speed: 1.3ms preprocess, 249.7ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 276.0ms\n",
      "Speed: 1.1ms preprocess, 276.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 287.9ms\n",
      "Speed: 1.1ms preprocess, 287.9ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 288.7ms\n",
      "Speed: 1.1ms preprocess, 288.7ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 291.8ms\n",
      "Speed: 1.1ms preprocess, 291.8ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 280.2ms\n",
      "Speed: 1.3ms preprocess, 280.2ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 265.5ms\n",
      "Speed: 1.2ms preprocess, 265.5ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 270.0ms\n",
      "Speed: 1.2ms preprocess, 270.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 264.4ms\n",
      "Speed: 1.1ms preprocess, 264.4ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 269.1ms\n",
      "Speed: 1.1ms preprocess, 269.1ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 274.9ms\n",
      "Speed: 1.2ms preprocess, 274.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 273.6ms\n",
      "Speed: 1.1ms preprocess, 273.6ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 277.5ms\n",
      "Speed: 1.2ms preprocess, 277.5ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 287.0ms\n",
      "Speed: 1.2ms preprocess, 287.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 268.3ms\n",
      "Speed: 1.4ms preprocess, 268.3ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 271.3ms\n",
      "Speed: 1.1ms preprocess, 271.3ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 266.9ms\n",
      "Speed: 1.1ms preprocess, 266.9ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 270.1ms\n",
      "Speed: 1.1ms preprocess, 270.1ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 272.7ms\n",
      "Speed: 1.4ms preprocess, 272.7ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 277.9ms\n",
      "Speed: 1.3ms preprocess, 277.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 265.5ms\n",
      "Speed: 1.1ms preprocess, 265.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 274.7ms\n",
      "Speed: 1.1ms preprocess, 274.7ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 269.1ms\n",
      "Speed: 1.1ms preprocess, 269.1ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 278.4ms\n",
      "Speed: 1.2ms preprocess, 278.4ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 271.5ms\n",
      "Speed: 1.2ms preprocess, 271.5ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 270.8ms\n",
      "Speed: 1.1ms preprocess, 270.8ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 262.1ms\n",
      "Speed: 1.1ms preprocess, 262.1ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 244.4ms\n",
      "Speed: 1.1ms preprocess, 244.4ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 244.9ms\n",
      "Speed: 1.2ms preprocess, 244.9ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 257.6ms\n",
      "Speed: 1.1ms preprocess, 257.6ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 271.7ms\n",
      "Speed: 1.2ms preprocess, 271.7ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 262.9ms\n",
      "Speed: 1.1ms preprocess, 262.9ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 277.7ms\n",
      "Speed: 1.2ms preprocess, 277.7ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 265.1ms\n",
      "Speed: 1.1ms preprocess, 265.1ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 275.3ms\n",
      "Speed: 1.1ms preprocess, 275.3ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 259.4ms\n",
      "Speed: 1.1ms preprocess, 259.4ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 282.6ms\n",
      "Speed: 1.1ms preprocess, 282.6ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 276.6ms\n",
      "Speed: 1.1ms preprocess, 276.6ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 278.0ms\n",
      "Speed: 1.2ms preprocess, 278.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 266.6ms\n",
      "Speed: 1.1ms preprocess, 266.6ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 266.0ms\n",
      "Speed: 1.2ms preprocess, 266.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 267.1ms\n",
      "Speed: 1.2ms preprocess, 267.1ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 263.4ms\n",
      "Speed: 1.2ms preprocess, 263.4ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 267.3ms\n",
      "Speed: 1.1ms preprocess, 267.3ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 271.9ms\n",
      "Speed: 1.1ms preprocess, 271.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 270.5ms\n",
      "Speed: 1.1ms preprocess, 270.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 267.8ms\n",
      "Speed: 1.1ms preprocess, 267.8ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 273.9ms\n",
      "Speed: 1.1ms preprocess, 273.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 273.8ms\n",
      "Speed: 1.1ms preprocess, 273.8ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 276.4ms\n",
      "Speed: 1.1ms preprocess, 276.4ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 271.0ms\n",
      "Speed: 1.2ms preprocess, 271.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 267.1ms\n",
      "Speed: 1.1ms preprocess, 267.1ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 270.7ms\n",
      "Speed: 1.2ms preprocess, 270.7ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 260.1ms\n",
      "Speed: 1.1ms preprocess, 260.1ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 256.8ms\n",
      "Speed: 2.0ms preprocess, 256.8ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 191.0ms\n",
      "Speed: 1.2ms preprocess, 191.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 188.1ms\n",
      "Speed: 1.0ms preprocess, 188.1ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 221.1ms\n",
      "Speed: 1.5ms preprocess, 221.1ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 198.5ms\n",
      "Speed: 1.2ms preprocess, 198.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 224.1ms\n",
      "Speed: 1.1ms preprocess, 224.1ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 150.9ms\n",
      "Speed: 1.1ms preprocess, 150.9ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 154.0ms\n",
      "Speed: 1.2ms preprocess, 154.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 153.3ms\n",
      "Speed: 1.1ms preprocess, 153.3ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 152.4ms\n",
      "Speed: 1.1ms preprocess, 152.4ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 162.2ms\n",
      "Speed: 1.1ms preprocess, 162.2ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 154.5ms\n",
      "Speed: 1.4ms preprocess, 154.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 154.8ms\n",
      "Speed: 1.1ms preprocess, 154.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 160.2ms\n",
      "Speed: 1.1ms preprocess, 160.2ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 153.3ms\n",
      "Speed: 1.3ms preprocess, 153.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 151.8ms\n",
      "Speed: 1.1ms preprocess, 151.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 156.8ms\n",
      "Speed: 1.1ms preprocess, 156.8ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 149.3ms\n",
      "Speed: 1.1ms preprocess, 149.3ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 151.0ms\n",
      "Speed: 1.0ms preprocess, 151.0ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 155.6ms\n",
      "Speed: 1.0ms preprocess, 155.6ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 165.9ms\n",
      "Speed: 1.4ms preprocess, 165.9ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 171.4ms\n",
      "Speed: 1.3ms preprocess, 171.4ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 176.1ms\n",
      "Speed: 1.1ms preprocess, 176.1ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 172.7ms\n",
      "Speed: 1.2ms preprocess, 172.7ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 262.3ms\n",
      "Speed: 1.3ms preprocess, 262.3ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 210.2ms\n",
      "Speed: 1.1ms preprocess, 210.2ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 184.8ms\n",
      "Speed: 1.0ms preprocess, 184.8ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 178.9ms\n",
      "Speed: 1.3ms preprocess, 178.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 173.9ms\n",
      "Speed: 1.2ms preprocess, 173.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 186.5ms\n",
      "Speed: 1.2ms preprocess, 186.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 183.3ms\n",
      "Speed: 1.0ms preprocess, 183.3ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 220.7ms\n",
      "Speed: 1.0ms preprocess, 220.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 195.5ms\n",
      "Speed: 1.0ms preprocess, 195.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 187.0ms\n",
      "Speed: 1.1ms preprocess, 187.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 181.7ms\n",
      "Speed: 1.1ms preprocess, 181.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 186.0ms\n",
      "Speed: 1.1ms preprocess, 186.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 186.3ms\n",
      "Speed: 1.0ms preprocess, 186.3ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 181.5ms\n",
      "Speed: 2.2ms preprocess, 181.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 183.2ms\n",
      "Speed: 2.0ms preprocess, 183.2ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 185.6ms\n",
      "Speed: 1.2ms preprocess, 185.6ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 179.9ms\n",
      "Speed: 1.0ms preprocess, 179.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 183.8ms\n",
      "Speed: 1.1ms preprocess, 183.8ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 194.7ms\n",
      "Speed: 1.1ms preprocess, 194.7ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 176.8ms\n",
      "Speed: 1.4ms preprocess, 176.8ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 187.5ms\n",
      "Speed: 1.1ms preprocess, 187.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 183.2ms\n",
      "Speed: 1.0ms preprocess, 183.2ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 183.6ms\n",
      "Speed: 1.0ms preprocess, 183.6ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 197.8ms\n",
      "Speed: 1.6ms preprocess, 197.8ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 178.3ms\n",
      "Speed: 1.0ms preprocess, 178.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 183.6ms\n",
      "Speed: 1.1ms preprocess, 183.6ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 180.3ms\n",
      "Speed: 1.0ms preprocess, 180.3ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 176.3ms\n",
      "Speed: 1.0ms preprocess, 176.3ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 188.4ms\n",
      "Speed: 1.2ms preprocess, 188.4ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 187.6ms\n",
      "Speed: 1.0ms preprocess, 187.6ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 181.9ms\n",
      "Speed: 1.0ms preprocess, 181.9ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 178.1ms\n",
      "Speed: 1.1ms preprocess, 178.1ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 185.0ms\n",
      "Speed: 1.4ms preprocess, 185.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 205.9ms\n",
      "Speed: 1.3ms preprocess, 205.9ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 181.4ms\n",
      "Speed: 1.0ms preprocess, 181.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 201.1ms\n",
      "Speed: 1.0ms preprocess, 201.1ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 181.1ms\n",
      "Speed: 1.0ms preprocess, 181.1ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 182.3ms\n",
      "Speed: 1.0ms preprocess, 182.3ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 183.8ms\n",
      "Speed: 1.0ms preprocess, 183.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 187.4ms\n",
      "Speed: 1.0ms preprocess, 187.4ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 187.0ms\n",
      "Speed: 1.0ms preprocess, 187.0ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 177.7ms\n",
      "Speed: 1.0ms preprocess, 177.7ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 182.3ms\n",
      "Speed: 1.0ms preprocess, 182.3ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 187.7ms\n",
      "Speed: 1.0ms preprocess, 187.7ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 183.8ms\n",
      "Speed: 1.0ms preprocess, 183.8ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 178.6ms\n",
      "Speed: 1.1ms preprocess, 178.6ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 180.4ms\n",
      "Speed: 1.0ms preprocess, 180.4ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 176.5ms\n",
      "Speed: 1.4ms preprocess, 176.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 188.1ms\n",
      "Speed: 1.1ms preprocess, 188.1ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 180.3ms\n",
      "Speed: 1.3ms preprocess, 180.3ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 184.4ms\n",
      "Speed: 1.0ms preprocess, 184.4ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 181.0ms\n",
      "Speed: 1.0ms preprocess, 181.0ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 183.2ms\n",
      "Speed: 1.0ms preprocess, 183.2ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 183.1ms\n",
      "Speed: 1.0ms preprocess, 183.1ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 183.1ms\n",
      "Speed: 1.0ms preprocess, 183.1ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 196.2ms\n",
      "Speed: 1.0ms preprocess, 196.2ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 191.1ms\n",
      "Speed: 1.2ms preprocess, 191.1ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 183.7ms\n",
      "Speed: 1.0ms preprocess, 183.7ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 185.4ms\n",
      "Speed: 1.0ms preprocess, 185.4ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 214.2ms\n",
      "Speed: 1.0ms preprocess, 214.2ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 182.8ms\n",
      "Speed: 1.0ms preprocess, 182.8ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 188.4ms\n",
      "Speed: 1.1ms preprocess, 188.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 183.6ms\n",
      "Speed: 1.2ms preprocess, 183.6ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 183.9ms\n",
      "Speed: 1.0ms preprocess, 183.9ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 196.4ms\n",
      "Speed: 0.9ms preprocess, 196.4ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "# Interactive Pygame Example: Drag and Move Car and Person with the Mouse\n",
    "import pygame\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "pygame.init()\n",
    "\n",
    "model = YOLO('model/yolov8n.pt')\n",
    "\n",
    "# Define window size\n",
    "WIDTH, HEIGHT = 800, 600\n",
    "screen = pygame.display.set_mode((WIDTH, HEIGHT))\n",
    "pygame.display.set_caption(\"Car and Person on Canvas\")\n",
    "\n",
    "WHITE = (255, 255, 255)\n",
    "\n",
    "# Load and scale images\n",
    "car_img = pygame.image.load(\"media/car.png\")\n",
    "person_img = pygame.image.load(\"media/person.png\")\n",
    "car_img = pygame.transform.scale(car_img, (300, 240))\n",
    "person_img = pygame.transform.scale(person_img, (300, 300))\n",
    "\n",
    "# Starting positions of the images\n",
    "car_pos = [200, 300]\n",
    "person_pos = [500, 300]\n",
    "\n",
    "# Dragging state flags\n",
    "dragging_auto = False\n",
    "dragging_person = False\n",
    "offset_x = 0\n",
    "offset_y = 0\n",
    "\n",
    "# Main loop\n",
    "running = True\n",
    "while running:\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT or (event.type == pygame.KEYDOWN and event.key == pygame.K_ESCAPE):\n",
    "            running = False\n",
    "\n",
    "        elif event.type == pygame.MOUSEBUTTONDOWN:\n",
    "            mouse_x, mouse_y = event.pos\n",
    "            # Check if mouse is over the car\n",
    "            if (car_pos[0] <= mouse_x <= car_pos[0] + car_img.get_width() and\n",
    "                car_pos[1] <= mouse_y <= car_pos[1] + car_img.get_height()):\n",
    "                dragging_auto = True\n",
    "                offset_x = mouse_x - car_pos[0]\n",
    "                offset_y = mouse_y - car_pos[1]\n",
    "            # Or over the person\n",
    "            elif (person_pos[0] <= mouse_x <= person_pos[0] + person_img.get_width() and\n",
    "                  person_pos[1] <= mouse_y <= person_pos[1] + person_img.get_height()):\n",
    "                dragging_person = True\n",
    "                offset_x = mouse_x - person_pos[0]\n",
    "                offset_y = mouse_y - person_pos[1]\n",
    "\n",
    "        elif event.type == pygame.MOUSEBUTTONUP:\n",
    "            dragging_auto = False\n",
    "            dragging_person = False\n",
    "\n",
    "        elif event.type == pygame.MOUSEMOTION:\n",
    "            if dragging_auto:\n",
    "                mouse_x, mouse_y = event.pos\n",
    "                car_pos[0] = mouse_x - offset_x\n",
    "                car_pos[1] = mouse_y - offset_y\n",
    "            elif dragging_person:\n",
    "                mouse_x, mouse_y = event.pos\n",
    "                person_pos[0] = mouse_x - offset_x\n",
    "                person_pos[1] = mouse_y - offset_y\n",
    "\n",
    "            \n",
    "    surface_to_draw = pygame.display.get_surface()\n",
    "    view = pygame.surfarray.array3d(surface_to_draw)\n",
    "    # Convert to OpenCV format\n",
    "    view = view.transpose((1, 0, 2))  # Change from (width, height, channels) to (height, width, channes)\n",
    "    # Convert to BGR format\n",
    "    # Display the image using OpenCV\n",
    "    view = cv2.cvtColor(view, cv2.COLOR_RGB2BGR)\n",
    "    result = model(view)\n",
    "    annotated_image = result[0].plot()\n",
    "    cv2.imshow(\"Carla View\", annotated_image)\n",
    "    # Update the display\n",
    "\n",
    "    # Draw canvas and images \n",
    "    screen.fill(WHITE)\n",
    "    screen.blit(car_img, car_pos)\n",
    "    screen.blit(person_img, person_pos)\n",
    "    pygame.display.flip()\n",
    "  \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pygame.quit()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481cd9b8",
   "metadata": {},
   "source": [
    "### ðŸ§  Task: Use OpenCV with YOLO on a Pygame Display\n",
    "\n",
    "> Modify the Pygame script above to achieve the following:\n",
    "- Capture the current Pygame display as an image\n",
    "- Convert it to a format compatible with OpenCV\n",
    "- Apply YOLO object detection to each frame\n",
    "- Display the annotated result in real time using OpenCV"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "carlaGE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "321.883px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
